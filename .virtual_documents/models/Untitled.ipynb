


import os
import shutil
import cv2
import imghdr

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf

from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay

from tensorflow import keras
from keras import Input
from keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom
from tensorflow.keras.utils import image_dataset_from_directory
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l1_l2

from PIL import Image, ImageOps


dog_labels = pd.read_csv(r"C:\Users\rockm\Desktop\GA\Projects\Capstone-dog\data\labels.csv")


dog_labels.head()


dog_labels.shape


data_dir = r"C:\Users\rockm\Desktop\GA\Projects\Capstone-dog\images\dog_emotions_complete"


dog_labels_cleaned = dog_labels[~dog_labels['filename'].isin(corrupted_images_to_remove)]


dog_labels_cleaned.shape


data = tf.keras.utils.image_dataset_from_directory(r"C:\Users\rockm\Desktop\GA\Projects\Capstone-dog\images\dog_emotions_complete")


#train_data = tf.keras.utils.image_dataset_from_directory('images/dog_emotion/train')


#test_data = tf.keras.utils.image_dataset_from_directory('images/dog_emotion/test')


data_iterator = data.as_numpy_iterator()


batch = data_iterator.next()


len(batch)


batch[0].shape


# label classification for images
batch[1]


# figuring out which number is assigned to which emotion
fig, ax = plt.subplots(ncols=4, figsize=(20,20))
for idx, img in enumerate(batch[0][:4]):
    ax[idx].imshow(img.astype(int))
    ax[idx].title.set_text(batch[1][idx])





# max and min RGB values for images


batch[0].max()


batch[0].min()


# scaling data
scaled_data = data.map(lambda x,y: (x/255, y))


scaled_iterator = scaled_data.as_numpy_iterator()


batch = scaled_iterator.next()


batch[0].max()


# running same loop again but with scaled images
fig, ax = plt.subplots(ncols=4, figsize=(20,20))
for idx, img in enumerate(batch[0][:4]):
    ax[idx].imshow(img)
    ax[idx].title.set_text(batch[1][idx])


# 125 batches
len(data)


train_size = int(len(scaled_data)*.7)
test_size = int(len(scaled_data)*.1)
val_size = int(len(scaled_data)*.2)+1


train_size + test_size + val_size


train = scaled_data.take(train_size)
val = scaled_data.skip(train_size).take(val_size)
test = scaled_data.skip(train_size+val_size).take(test_size)


len(test)





train_datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)


val_datagen = ImageDataGenerator()

train_generator = train_datagen.flow_from_directory(
    r"C:\Users\rockm\Desktop\GA\Projects\Capstone-dog\images\dog_emotions_split\train",
    target_size=(256, 256),
    batch_size=32,
    class_mode='sparse'
)

val_generator = val_datagen.flow_from_directory(
    r"C:\Users\rockm\Desktop\GA\Projects\Capstone-dog\images\dog_emotions_split\val",
    target_size=(256, 256),
    batch_size=32,
    class_mode='sparse'
)


model = Sequential()


model.add(Input(shape=(256, 256, 3))),
#model.add(RandomFlip('horizontal_and_vertical')),
#model.add(RandomRotation(0.2)),
#model.add(RandomZoom(height_factor=(-0.2, 0.2), width_factor=(-0.2, 0.2))),
model.add(Conv2D(16, (3,3), 1, activation='relu'))
model.add(MaxPooling2D())

model.add(Conv2D(32, (3,3), 1, activation='relu'))
model.add(MaxPooling2D())

model.add(Conv2D(16, (3, 3), activation='relu')),
model.add(MaxPooling2D(2)),

#model.add(Conv2D(128, (3,3), 1, activation='relu'))
#model.add(MaxPooling2D())

#model.add(Conv2D(256, (3,3), 1, activation='relu'))
#model.add(MaxPooling2D())

model.add(Flatten())

model.add(Dense(256, activation='relu'))
#model.add(Dense(128, activation='relu'))
#model.add(Dense(64, activation='relu'))
model.add(Dense(4, activation='softmax'))


#model.compile('adam', loss=tf.keras.losses.categorical_crossentropy(), metrics=['accuracy'])


model.compile(
    loss='sparse_categorical_crossentropy',
    optimizer='Adamax',
    metrics=['acc']
)


model.summary()


# Training model


logdir = 'logs'


tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)


#hist = model.fit(train_generator, epochs=20, validation_data=val_generator, callbacks=[tensorboard_callback])


#hist = model.fit(train, epochs=20, validation_data = val, callbacks=[tensorboard_callback])


vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))


for layer in vgg16_base.layers:
    layer.trainable = False


model2 = Sequential([
    vgg16_base,
    GlobalAveragePooling2D(),
    Dense(224, activation='relu'),
    Dense(4, activation='softmax')
])


model2.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])


train_generator = train_datagen.flow_from_directory(
    r"C:\Users\rockm\Desktop\GA\Projects\Capstone-dog\images\dog_emotions_split\train",
    target_size=(224, 224),
    batch_size=32,
    class_mode='sparse'
)

val_generator = val_datagen.flow_from_directory(
    r"C:\Users\rockm\Desktop\GA\Projects\Capstone-dog\images\dog_emotions_split\val",
    target_size=(224, 224),
    batch_size=32,
    class_mode='sparse'
)


early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

history = model2.fit(
    train_generator,
    epochs=25,
    validation_data=val_generator,
    callbacks=[early_stopping]
)


vgg16_base2 = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))


model3 = Sequential([
    vgg16_base2,
    GlobalAveragePooling2D(),
    Dense(256, activation='relu'),
    Dense(4, activation='softmax')
])


early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)


checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath='best_model.weights.h5',
    monitor='val_loss',        
    save_best_only=True,       
    save_weights_only=True,   
    mode='min',                
    verbose=1
)


model3.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])


model_json = model3.to_json()
with open('model_architecture.json', 'w') as json_file:
    json_file.write(model_json)


hist = model3.fit(train, epochs=25, validation_data = val, callbacks=[early_stopping, checkpoint_callback])


import json


model_json = model3.to_json()
with open('model_architecture.json', 'w') as json_file:
    json_file.write(model_json)


with open('model_architecture.json', 'r') as json_file:
    model_json = json_file.read()


model3 = tf.keras.models.model_from_json(model_json)


model3.summary()





vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))


for layer in vgg16_base.layers:
    layer.trainable = False


model3 = Sequential([
    vgg16_base,
    GlobalAveragePooling2D(),
    Dense(224, activation='relu'),
    Dropout(0.5),
    Dense(4, activation='softmax')
])


model3.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])


model3.summary()


train_generator = train_datagen.flow_from_directory(
    r"C:\Users\rockm\Desktop\GA\Projects\Capstone-dog\images\dog_emotions_split\train",
    target_size=(224, 224),
    batch_size=32,
    class_mode='sparse'
)

val_generator = val_datagen.flow_from_directory(
    r"C:\Users\rockm\Desktop\GA\Projects\Capstone-dog\images\dog_emotions_split\val",
    target_size=(224, 224),
    batch_size=32,
    class_mode='sparse'
)


early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

history = model3.fit(
    train_generator,
    epochs=25,
    validation_data=val_generator,
    callbacks=[early_stopping]
)





from tensorflow.keras.optimizers import AdamW


vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))


for layer in vgg16_base.layers:
    layer.trainable = False


model4 = Sequential([
    vgg16_base,
    GlobalAveragePooling2D(),
    Dense(224, activation='relu'),
    Dense(4, activation='softmax')
])


model4.compile(optimizer=AdamW(learning_rate=0.0001, weight_decay=0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])


train_generator = train_datagen.flow_from_directory(
    r"C:\Users\rockm\Desktop\GA\Projects\Capstone-dog\images\dog_emotions_split\train",
    target_size=(224, 224),
    batch_size=32,
    class_mode='sparse'
)

val_generator = val_datagen.flow_from_directory(
    r"C:\Users\rockm\Desktop\GA\Projects\Capstone-dog\images\dog_emotions_split\val",
    target_size=(224, 224),
    batch_size=32,
    class_mode='sparse'
)

early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

history = model4.fit(
    train_generator,
    epochs=25,
    validation_data=val_generator,
    callbacks=[early_stopping]
)


from tensorflow.keras.models import load_model
best_model = load_model('best_model.keras')


!python -v



