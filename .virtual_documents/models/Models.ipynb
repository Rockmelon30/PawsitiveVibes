





#pip install opencv-python


import os
import shutil
import cv2
import imghdr
import json

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
import seaborn as sns

from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay

from tensorflow import keras
from keras import Input
from keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom
from tensorflow.keras.utils import image_dataset_from_directory
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l1_l2

from PIL import Image, ImageOps


#pip uninstall tensorflow


#pip install tensorflow


#pip list


#importing labels for images
labels_cleaned = pd.read_csv(r"C:\Users\rockm\Desktop\GA\Projects\Capstone-dog\data\labels_cleaned.csv")


dataset_path = r"C:\Users\rockm\Desktop\GA\Projects\Capstone-dog\images\dog_emotions_split\train"


class_names = sorted(os.listdir(dataset_path))
num_classes = len(class_names)
image_size = (256, 256)


print(f'{num_classes} classes: {class_names}\nimage size: {image_size}')


images = []
labels = []


train_ds = image_dataset_from_directory(
    dataset_path,
    batch_size=32,
    image_size=image_size,
    subset='training',
    seed=42,
    validation_split=0.2,
    class_names=['angry', 'happy', 'relaxed', 'sad']
).map(lambda x, y: (x/255, y))

val_ds = image_dataset_from_directory(
    dataset_path,
    batch_size=32,
    image_size=image_size,
    subset='validation',
    seed=42,
    validation_split=0.2,
    class_names=['angry', 'happy', 'relaxed', 'sad']
).map(lambda x, y: (x/255, y))


train_ds = train_ds.map(lambda x, y: (x, tf.one_hot(y, depth=4)))
val_ds = val_ds.map(lambda x, y: (x, tf.one_hot(y, depth=4)))


#train_ds


for x, y in train_ds:
    break


plt.imshow(x[4]);


data = tf.keras.utils.image_dataset_from_directory(r"C:\Users\rockm\Desktop\GA\Projects\Capstone-dog\images\dog_emotions_complete")


#train_data = tf.keras.utils.image_dataset_from_directory('images/dog_emotion/train')


#test_data = tf.keras.utils.image_dataset_from_directory('images/dog_emotion/test')


data_iterator = data.as_numpy_iterator()


batch = data_iterator.next()


len(batch)


batch[0].shape


# label classification for images
batch[1]


# figuring out which number is assigned to which emotion
fig, ax = plt.subplots(ncols=4, figsize=(20,20))
for idx, img in enumerate(batch[0][:4]):
    ax[idx].imshow(img.astype(int))
    ax[idx].title.set_text(batch[1][idx])








model = keras.models.Sequential([
    Input(shape=(256, 256, 3)),
    
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(2),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(2),
    
    Conv2D(128, (2, 2), activation='relu'),
    MaxPooling2D(2),
    Conv2D(128, (2, 2), activation='relu'),
    MaxPooling2D(2),
    
    Conv2D(256, (2, 2), activation='relu'),
    MaxPooling2D(2),
    Conv2D(256, (2, 2), activation='relu'),
    MaxPooling2D(2),
    
    Conv2D(512, (2, 2), activation='relu'),
    Flatten(),

    Dense(256, activation='relu'),
    Dense(128, activation='relu'),
    #Dropout(0.5),
    Dense(64, activation='relu'),
    #Dropout(0.5),
    Dense(4, activation='softmax')
])

model.compile(
    loss='categorical_crossentropy',
    optimizer='Adamax',
    metrics=['acc']
)


model.summary()


early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)


model.fit(train_ds, validation_data=val_ds, epochs=25, callbacks=[early_stopping]);





model2 = keras.models.Sequential([
    Input(shape=(256, 256, 3)),
    RandomFlip('horizontal_and_vertical'),
    RandomRotation(0.2),
    RandomZoom(height_factor=(-0.2, 0.2), width_factor=(-0.2, 0.2)),
    
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(2),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(2),
    
    Conv2D(128, (2, 2), activation='relu'),
    MaxPooling2D(2),
    Conv2D(128, (2, 2), activation='relu'),
    MaxPooling2D(2),
    
    Conv2D(256, (2, 2), activation='relu'),
    MaxPooling2D(2),
    Conv2D(256, (2, 2), activation='relu'),
    MaxPooling2D(2),
    
    Conv2D(512, (2, 2), activation='relu'),
    Flatten(),

    Dense(256, activation='relu'),
    Dense(128, activation='relu'),
    #Dropout(0.5),
    Dense(64, activation='relu'),
    #Dropout(0.5),
    Dense(4, activation='softmax')
])

model2.compile(
    loss='categorical_crossentropy',
    optimizer='Adamax',
    metrics=['acc']
)


model2.summary()


model2.fit(train_ds, validation_data=val_ds, epochs=50, callbacks=[early_stopping]);





# max and min RGB values for images
batch[0].max()


batch[0].min()


# scaling data
scaled_data = data.map(lambda x,y: (x/255, y))


scaled_iterator = scaled_data.as_numpy_iterator()


# running same loop again but with scaled images
fig, ax = plt.subplots(ncols=4, figsize=(20,20))
for idx, img in enumerate(batch[0][:4]):
    ax[idx].imshow(img)
    ax[idx].title.set_text(batch[1][idx])


# 125 batches
len(data)


train_size = int(len(scaled_data)*.7)
test_size = int(len(scaled_data)*.1)
val_size = int(len(scaled_data)*.2)+1


train_size + test_size + val_size


train = scaled_data.take(train_size)
val = scaled_data.skip(train_size).take(val_size)
test = scaled_data.skip(train_size+val_size).take(test_size)


len(test)





train_datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)


val_datagen = ImageDataGenerator()

train_generator = train_datagen.flow_from_directory(
    r"C:\Users\rockm\Desktop\GA\Projects\Capstone-dog\images\dog_emotions_split\train",
    target_size=(256, 256),
    batch_size=32,
    class_mode='sparse'
)

val_generator = val_datagen.flow_from_directory(
    r"C:\Users\rockm\Desktop\GA\Projects\Capstone-dog\images\dog_emotions_split\val",
    target_size=(256, 256),
    batch_size=32,
    class_mode='sparse'
)

test_generator = val_datagen.flow_from_directory(
    r"C:\Users\rockm\Desktop\GA\Projects\Capstone-dog\images\dog_emotions_split\val",
    target_size=(256, 256),
    batch_size=32,
    class_mode='sparse'
)


model3 = Sequential()


model3.add(Input(shape=(256, 256, 3))),
#model3.add(RandomFlip('horizontal_and_vertical')),
#model3.add(RandomRotation(0.2)),
#model3.add(RandomZoom(height_factor=(-0.2, 0.2), width_factor=(-0.2, 0.2))),
model3.add(Conv2D(16, (3,3), 1, activation='relu'))
model3.add(MaxPooling2D())

model3.add(Conv2D(32, (3,3), 1, activation='relu'))
model3.add(MaxPooling2D())

model3.add(Conv2D(16, (3, 3), activation='relu')),
model3.add(MaxPooling2D(2)),

#model3.add(Conv2D(128, (3,3), 1, activation='relu'))
#model3.add(MaxPooling2D())

#model3.add(Conv2D(256, (3,3), 1, activation='relu'))
#model3.add(MaxPooling2D())

model3.add(Flatten())

model3.add(Dense(256, activation='relu'))
#model3.add(Dense(128, activation='relu'))
#model3.add(Dense(64, activation='relu'))
model3.add(Dense(4, activation='softmax'))


#model3.compile('adam', loss=tf.keras.losses.categorical_crossentropy(), metrics=['accuracy'])


model3.compile(
    loss='sparse_categorical_crossentropy',
    optimizer='Adamax',
    metrics=['acc']
)


model3.summary()


# Training model
logdir = 'logs'


tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)


#hist = model3.fit(train_generator, epochs=20, validation_data=val_generator, callbacks=[tensorboard_callback])


#hist = model3.fit(train, epochs=20, validation_data = val, callbacks=[tensorboard_callback])





vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))


for layer in vgg16_base.layers:
    layer.trainable = False


model4 = Sequential([
    vgg16_base,
    GlobalAveragePooling2D(),
    Dense(224, activation='relu'),
    Dense(4, activation='softmax')
])


model4.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])


train_generator = train_datagen.flow_from_directory(
    r"C:\Users\rockm\Desktop\GA\Projects\Capstone-dog\images\dog_emotions_split\train",
    target_size=(224, 224),
    batch_size=32,
    class_mode='sparse'
)

val_generator = val_datagen.flow_from_directory(
    r"C:\Users\rockm\Desktop\GA\Projects\Capstone-dog\images\dog_emotions_split\val",
    target_size=(224, 224),
    batch_size=32,
    class_mode='sparse'
)


early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

history = model4.fit(
    train_generator,
    epochs=25,
    validation_data=val_generator,
    callbacks=[early_stopping]
)





vgg16_base2 = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))


model5 = Sequential([
    vgg16_base2,
    GlobalAveragePooling2D(),
    Dense(256, activation='relu'),
    Dense(4, activation='softmax')
])


model5.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])


checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath='best_model2.keras',
    monitor='val_loss',        
    save_best_only=True,       
    save_weights_only=False,   
    mode='min',                
    verbose=1                  
)


hist5 = model5.fit(train, epochs=25, validation_data = val, callbacks=[early_stopping, checkpoint_callback])


y_val_pred_probs = model5.predict(val)
y_val_pred_classes = np.argmax(y_val_pred_probs, axis=1)


y_val_true = []
for _, labels in val:
    y_val_true.extend(np.argmax(labels.numpy(), axis=1))

y_val_true = np.array(y_val_true)


# Generate the confusion matrix
cm = confusion_matrix(y_val_true, y_val_pred_classes)

# Plot the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['angry', 'happy', 'relaxed', 'sad'],
            yticklabels=['angry', 'happy', 'relaxed', 'sad'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()


model5.summary()


model_json = model5.to_json()
with open('model_architecture.json', 'w') as json_file:
    json_file.write(model_json)


with open('model_architecture.json', 'r') as json_file:
    model_json = json_file.read()


model5 = tf.keras.models.model_from_json(model_json)





vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))


for layer in vgg16_base.layers:
    layer.trainable = False


model6 = Sequential([
    vgg16_base,
    GlobalAveragePooling2D(),
    Dense(224, activation='relu'),
    Dropout(0.5),
    Dense(4, activation='softmax')
])


model6.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])


model6.summary()


train_generator = train_datagen.flow_from_directory(
    r"C:\Users\rockm\Desktop\GA\Projects\Capstone-dog\images\dog_emotions_split\train",
    target_size=(224, 224),
    batch_size=32,
    class_mode='sparse'
)

val_generator = val_datagen.flow_from_directory(
    r"C:\Users\rockm\Desktop\GA\Projects\Capstone-dog\images\dog_emotions_split\val",
    target_size=(224, 224),
    batch_size=32,
    class_mode='sparse'
)


early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

history = model6.fit(
    train_generator,
    epochs=25,
    validation_data=val_generator,
    callbacks=[early_stopping]
)





from tensorflow.keras.optimizers import AdamW


vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))


for layer in vgg16_base.layers:
    layer.trainable = False


model7 = Sequential([
    vgg16_base,
    GlobalAveragePooling2D(),
    Dense(224, activation='relu'),
    Dense(4, activation='softmax')
])


model7.compile(optimizer=AdamW(learning_rate=0.0001, weight_decay=0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])


train_generator = train_datagen.flow_from_directory(
    r"C:\Users\rockm\Desktop\GA\Projects\Capstone-dog\images\dog_emotions_split\train",
    target_size=(224, 224),
    batch_size=32,
    class_mode='sparse'
)

val_generator = val_datagen.flow_from_directory(
    r"C:\Users\rockm\Desktop\GA\Projects\Capstone-dog\images\dog_emotions_split\val",
    target_size=(224, 224),
    batch_size=32,
    class_mode='sparse'
)

early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

history = model7.fit(
    train_generator,
    epochs=25,
    validation_data=val_generator,
    callbacks=[early_stopping]
)





# Couldn't get this to work, there appears to be an issue between VGG16 and tensorflow versions 2.16.1+

#from tensorflow.keras.models import load_model
#best_model = load_model('best_model2.keras')



